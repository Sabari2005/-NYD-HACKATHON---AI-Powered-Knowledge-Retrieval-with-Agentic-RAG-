{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlz0H-HHP61M"
      },
      "source": [
        "##### Install necessary packages for working with Pinecone, sentence embeddings, and data manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dZbuZm5HPBUB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pinecone-client in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.0.1)\n",
            "Requirement already satisfied: sentence-transformers in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (2.2.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.4.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.25.1)\n",
            "Requirement already satisfied: Pillow in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\yvarajan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pinecone-client sentence-transformers pandas\n",
        "!pip install groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F8EVpq9RrYX"
      },
      "source": [
        "##### Install necessary packages for working with Pinecone, sentence embeddings, and data manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eorTMRj1QDMC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\yvarajan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\yvarajan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "from groq import Groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHn6BBKrR4XS"
      },
      "source": [
        "The code initializes a connection to the Pinecone vector database and sets up or selects an index to store data. It configures the index if needed, specifying its size and how similarity is measured. Finally, it establishes a connection to the specific index and prints a confirmation message.\n",
        "\n",
        "In essence, the code ensures the connection to Pinecone and sets up the designated area (index) where your data will be stored and accessed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rm3hPmKbQG1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to index: nyd\n"
          ]
        }
      ],
      "source": [
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=\"pcsk_6E9B6o_DHFJaybC7zzr4QT9i1tZo1vExTxji5j1syULud17p1HXAzrZPN7Zv4fs9H83L98\")  # Replace with your Pinecone API key\n",
        "\n",
        "index_name = \"nyd\"\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,        # Adjust based on your embedding dimension\n",
        "        metric='cosine',      # Use cosine similarity\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )\n",
        "index = pc.Index(index_name)\n",
        "print(f\"Connected to index: {index_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KD-wqzbUQJZs"
      },
      "outputs": [],
      "source": [
        "# Load Sentence Transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## this code uploads the dataset again into pinecone \n",
        "### we request you to not to run this cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wDsZ58ymQK1F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings with metadata uploaded to Pinecone!\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the dataset\n",
        "df = pd.read_csv(\"total_dataset.csv\")\n",
        "df['Combined_Questions'] = df['question'].apply(lambda x: \" \".join(x.split(\"?\")).strip())\n",
        "embeddings = model.encode(df['Combined_Questions'].tolist(), convert_to_numpy=True)\n",
        "\n",
        "# Upload embeddings and metadata to Pinecone\n",
        "for i, row in df.iterrows():\n",
        "    metadata = {\n",
        "        \"answer\": row['answer'],\n",
        "        \"chapter\": row['chapter'],\n",
        "        \"verse\": row['verse'],\n",
        "        \"sanskrit\": row['sanskrit']\n",
        "    }\n",
        "    index.upsert([(str(i), embeddings[i].tolist(), metadata)])\n",
        "print(\"Embeddings with metadata uploaded to Pinecone!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5unNu6vDQMfn"
      },
      "outputs": [],
      "source": [
        "# Function to retrieve answers and metadata from Pinecone\n",
        "def retrieve_answer(input_question, top_k=3):\n",
        "    query_embedding = model.encode(input_question, convert_to_numpy=True)\n",
        "    result = index.query(\n",
        "        vector=query_embedding.tolist(),\n",
        "        top_k=top_k,\n",
        "        include_metadata=True\n",
        "    )\n",
        "    answers = []\n",
        "    for match in result['matches']:\n",
        "        metadata = match['metadata']\n",
        "        answers.append({\n",
        "            \"score\": match['score'],\n",
        "            \"answer\": metadata['answer'],\n",
        "            \"chapter\": metadata.get('chapter', 'N/A'),\n",
        "            \"verse\": metadata.get('verse', 'N/A'),\n",
        "            \"sanskrit\": metadata.get('sanskrit', 'N/A')\n",
        "        })\n",
        "    return answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a0GLTN2YQN2U"
      },
      "outputs": [],
      "source": [
        "# Initialize Groq client for Llama\n",
        "client = Groq(api_key=\"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\")  # Replace with your Groq API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xcfcph0bQO_2"
      },
      "outputs": [],
      "source": [
        "def answer_query_from_llama(query):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"You are an assistant specialized in answering questions strictly based on the Bhagavad Gita and Patanjali Yoga Sutra. Provide the Bookname, chapter, verse, Sanskrit text, and a detailed answer to the following question: \\n {query}.\\n If the query is not related to it just give 'none' with no extra words.\"\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lEh-l0guQRBw"
      },
      "outputs": [],
      "source": [
        "# Llama Query Refinement\n",
        "def refine_query_with_llama(query, retrieved_info):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"You are an assistant specializing in refining queries for better retrieval only in Bhagavad Gita and Patanjali yoga sutra. \"\n",
        "                           f\"Original query: '{query}'\\n\"\n",
        "                           f\"Retrieved information:\\n{retrieved_info}\\n\"\n",
        "                           \"Refine the query to include specific details for improved results. \"\n",
        "                           \"If the query is not related to Bhagavad Gita and Pantanjali yoga sutra return it unchaged\"\n",
        "                           \"If the query is already precise, return it unchanged. Refined query:\"\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AauZpnJjQWJX"
      },
      "outputs": [],
      "source": [
        "# Llama Final Response Generation\n",
        "def generate_final_response_with_llama(query, retrieved_info, llm_retrieved):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"You are an expert at combining information to generate detailed answers. \"\n",
        "                           f\"Original query: '{query}'\\n\"\n",
        "                           f\"Retrieved information from semantic search:\\n{retrieved_info}\\n\"\n",
        "                           f\"Retrieved information from Llama:\\n{llm_retrieved}\\n\"\n",
        "                            \"Provide Bookname, chapter, verse, sanskrit, traslation if the query is directly belongs to sanskrit\\n\"\n",
        "                            \"If the query is not directly related to Bhagavad Gita and Pantanjali yoga sutra return 'This Question not directly related to Bhagavad Gita or Pantanjali yoga sutra' with no extra words\"\n",
        "                            \"Don't say how you process this context in the answer\"\n",
        "                            \"Using all the provided context, generate a complete, accurate, and concise answer.\"\n",
        "                            \"Provide the output in the following dictionary format within double quotes for keys and values: \\n\\n{{\\n  Book_name' : <Book_name>,\\n  'chapter': <chapter_number>,\\n  'verse': <verse_number>,\\n  'sanskrit': <sanskrit_text>,\\n  'Translation' : <Translation>,\\n  'answer': <enlarge_answer>\\n}}\\n\\n\"\n",
        "\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## generating answers in JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ReTV_EFbQbvX"
      },
      "outputs": [],
      "source": [
        "def final_resp(query_test):\n",
        "  user_query =query_test\n",
        "\n",
        "  # Step 1: Retrieve answer from Pinecone\n",
        "  semantic_results = retrieve_answer(user_query, top_k=3)\n",
        "\n",
        "  retrieved_info = \"\\n\".join([\n",
        "      f\"Score: {item['score']}, Answer: {item['answer']}, Chapter: {item['chapter']}, Verse: {item['verse']}, Sanskrit: {item['sanskrit']}\"\n",
        "      for item in semantic_results\n",
        "  ])\n",
        "\n",
        "  # Step 2: Retrieve answer from Llama\n",
        "  llm_result = answer_query_from_llama(user_query)\n",
        "\n",
        "  # Step 3: Refine the query with Llama\n",
        "  refined_query = refine_query_with_llama(user_query, retrieved_info)\n",
        "\n",
        "  # Step 4: Generate final response using Llama\n",
        "  final_response = generate_final_response_with_llama(refined_query, retrieved_info, llm_result)\n",
        "\n",
        "  # Display the results\n",
        "  print(\"=====================================================\")\n",
        "  print(\"Semantic Search Results:\")\n",
        "  print(retrieved_info)\n",
        "  print(\"-----------------------------------------------------\")\n",
        "  print(llm_result)\n",
        "  print(\"=====================================================\")\n",
        "  print(f\"Refined Query: {refined_query}\")\n",
        "  print(\"-----------------------------------------------------\")\n",
        "  print(f\"Final Response:\\n{final_response}\")\n",
        "  print(\"=====================================================\")\n",
        "  return final_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sfuR8bspQdAD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====================================================\n",
            "Semantic Search Results:\n",
            "Score: 0.529354334, Answer: The origin and destruction of beings have been heard in detail from You, O lotus-eyed Lord, and also Your inexhaustible greatness., Chapter: 11.0, Verse: 2.0, Sanskrit: भवाप्ययौ हि भूतानां श्रुतौ विस्तरशो मया| त्वत्तः कमलपत्राक्ष माहात्म्यमपि चाव्ययम् || 11.2 || \n",
            "Score: 0.519790769, Answer: The Blessed Lord said, \"O Arjuna, hear how you shall, without doubt, know Me fully, with your mind intent on Me, practicing Yoga and taking refuge in Me.\", Chapter: 7.0, Verse: 1.0, Sanskrit: मय्यासक्तमनाः पार्थ योगं युञ्जन्मदाश्रयः| असंशयं समग्रं मां यथा ज्ञास्यसि तच्छृणु || 7.1 || \n",
            "Score: 0.513937712, Answer: I will declare to you in full this knowledge combined with realization, after knowing which nothing else remains to be known here., Chapter: 7.0, Verse: 2.0, Sanskrit: ज्ञानं तेऽहं सविज्ञानमिदं वक्ष्याम्यशेषतः| यज्ज्ञात्वा नेह भूयोऽन्यज्ज्ञातव्यमवशिष्यते || 7.2 || \n",
            "-----------------------------------------------------\n",
            "Bookname: Bhagavad Gita\n",
            "Chapter: 10\n",
            "Verse: 8\n",
            "Sanskrit text: अहं सर्वस्य प्रभावो मत्तः सर्वं प्रवर्तते । इति मत्वा भजन्ते मां भूतानि बहुज्ञाज्ञसमेतानि || 8 ||\n",
            "Translation and Answer: \n",
            "The Bhagavad Gita is a dialogue between two main characters: Prince Arjuna and Lord Krishna. In this context, the question \"who is Bhagavad Gita\" seems to be inquiring about the nature or essence of the Bhagavad Gita, rather than a direct question about an entity called \"Bhagavad Gita\". \n",
            "\n",
            "However, in chapter 10, verse 8, Lord Krishna explains his profound influence on the universe, stating, \"I am the source of everything; everything emanates from me. The wise who know this worship me with devotion.\" Here, Lord Krishna, who is often considered the embodiment of the Bhagavad Gita's teachings, is discussing his divine nature and his role as the ultimate reality from which everything originates.\n",
            "\n",
            "In essence, the Bhagavad Gita is not a \"who\" but rather a sacred Hindu scripture that contains the teachings of Lord Krishna to Prince Arjuna on the nature of reality, duty (dharma), and the path to spiritual growth and self-realization. It is a text that explores various aspects of yoga, including the path of devotion (bhakti yoga), the path of knowledge (jnana yoga), and the path of action (karma yoga), providing guidance on how to live a meaningful and fulfilling life.\n",
            "=====================================================\n",
            "Refined Query: The original query 'who is Bhagavad Gita?' is unclear, as Bhagavad Gita is a scripture and not a person. However, it can be refined to ask about the author, the main character, or the speaker of the Bhagavad Gita.\n",
            "\n",
            "Refined query: 'Who is the speaker of the Bhagavad Gita?' or 'Who is the author of the Bhagavad Gita?' or 'Who is the main character in the Bhagavad Gita?' \n",
            "\n",
            "These refined queries can provide more accurate and relevant results. \n",
            "\n",
            "Refined query: 'Who is the speaker of the Bhagavad Gita?'\n",
            "-----------------------------------------------------\n",
            "Final Response:\n",
            "{\n",
            "  \"Book_name\" : \"Bhagavad Gita\",\n",
            "  \"chapter\" : 10,\n",
            "  \"verse\" : 8,\n",
            "  \"sanskrit\" : \"अहं सर्वस्य प्रभावो मत्तः सर्वं प्रवर्तते । इति मत्वा भजन्ते मां भूतानि बहुज्ञाज्ञसमेतानि\",\n",
            "  \"Translation\" : \"I am the source of everything; everything emanates from me. The wise who know this worship me with devotion.\",\n",
            "  \"answer\" : \"The speaker of the Bhagavad Gita is Lord Krishna, who is often considered the embodiment of the Bhagavad Gita's teachings, and is discussing his divine nature and his role as the ultimate reality from which everything originates.\"\n",
            "}\n",
            "=====================================================\n",
            "Saved JSON file for this Question : output_folder/output_.json\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import json\n",
        "import os\n",
        "\n",
        "query_test = input(\"Enter the Question: \")\n",
        "# Get the response from the final_resp function\n",
        "final_dic = final_resp(query_test)\n",
        "output_folder = \"output_folder\"\n",
        "\n",
        "try:\n",
        "  # Convert the JSON string to a Python dictionary\n",
        "  parsed_dict = json.loads(final_dic)\n",
        "\n",
        "\n",
        "# Save the parsed dictionary as a JSON file\n",
        "  json_filename = f\"{output_folder}/output_.json\"\n",
        "  with open(json_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
        "      json.dump(parsed_dict, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "  print(f\"Saved JSON file for this Question : {json_filename}\")\n",
        "except json.JSONDecodeError as e:\n",
        "  print(f\"Error decoding JSON for this Question : {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
